#!/usr/bin/env bash

# help.sh - Comprehensive help system for curllm

# Function to display basic help
show_basic_help() {
    echo "curllm - Universal LLM API Wrapper"
    echo "Version: v0.1.0"
    echo ""
    echo "USAGE:"
    echo "  curllm [COMMAND] [OPTIONS] [ARGUMENTS]"
    echo ""
    echo "COMMANDS:"
    echo "  chat <prompt>     Send a chat completion request to an LLM"
    echo "  help             Show this help message"
    echo "  version          Show version information"
    echo ""
    echo "BASIC EXAMPLES:"
    echo "  curllm chat \"What is the capital of France?\""
    echo "  curllm chat --provider qwen \"Explain quantum computing\""
    echo "  curllm chat --provider groq --model llama3-8b-8192 \"Write a Python function\""
    echo ""
    echo "For detailed documentation, visit: https://github.com/AR-92/curllm"
    echo "Use 'curllm help --verbose' for comprehensive help"
}

# Function to display verbose help
show_verbose_help() {
    echo "curllm - Universal LLM API Wrapper"
    echo "================================"
    echo ""
    echo "A powerful, pure Bash LLM API wrapper that provides a unified interface"
    echo "to interact with multiple Large Language Model providers."
    echo ""
    echo "SUPPORTED PROVIDERS:"
    echo "  openai      OpenAI GPT models (gpt-3.5-turbo, gpt-4, etc.)"
    echo "  anthropic   Anthropic Claude models (claude-2, claude-instant, etc.)"
    echo "  qwen        Alibaba Qwen models (qwen-turbo, qwen-plus, etc.)"
    echo "  mistral     Mistral AI models (mistral-tiny, mistral-small, etc.)"
    echo "  gemini      Google Gemini models (gemini-pro, gemini-pro-vision, etc.)"
    echo "  openrouter  OpenRouter models (100+ models from various providers)"
    echo "  groq        Groq models (llama2, llama3, mixtral, etc.)"
    echo ""
    echo "USAGE:"
    echo "  curllm COMMAND [OPTIONS] [ARGUMENTS]"
    echo ""
    echo "COMMANDS:"
    echo "  chat <prompt>"
    echo "      Send a chat completion request to an LLM provider"
    echo "      Arguments:"
    echo "        prompt    The text prompt to send to the LLM"
    echo ""
    echo "  help"
    echo "      Show help information"
    echo "      Options:"
    echo "        --verbose    Show detailed help information"
    echo ""
    echo "  version"
    echo "      Show version information"
    echo ""
    echo "OPTIONS:"
    echo "  --provider <name>"
    echo "      Specify the LLM provider to use"
    echo "      Default: openai"
    echo "      Values: openai, anthropic, qwen, mistral, gemini, openrouter, groq"
    echo ""
    echo "  --model <name>"
    echo "      Specify the model to use"
    echo "      Default: Provider-specific (e.g., gpt-3.5-turbo for OpenAI)"
    echo "      Examples: gpt-4, claude-2, qwen-turbo, llama3-8b-8192"
    echo ""
    echo "  --verbose"
    echo "      Enable verbose logging for debugging"
    echo "      Creates detailed logs in ~/.cache/curllm/curllm.log"
    echo ""
    echo "  --help, -h"
    echo "      Show help information"
    echo ""
    echo "  --version, -v"
    echo "      Show version information"
    echo ""
    echo "CONFIGURATION:"
    echo "  Configuration file: ~/.config/curllm/config"
    echo "  Required: API keys for each provider you want to use"
    echo "  Example config:"
    echo "    DEFAULT_PROVIDER=openai"
    echo "    DEFAULT_MODEL=gpt-3.5-turbo"
    echo "    OPENAI_API_KEY=sk-your-key"
    echo "    ANTHROPIC_API_KEY=your-key"
    echo ""
    echo "ENVIRONMENT VARIABLES:"
    echo "  MOCK_MODE=true        Enable mock mode (no real API calls)"
    echo "  XDG_CONFIG_HOME       Configuration directory (default: ~/.config)"
    echo "  XDG_CACHE_HOME        Log directory (default: ~/.cache)"
    echo ""
    echo "EXAMPLES:"
    echo "  # Basic usage with default provider"
    echo "  curllm chat \"What is the capital of France?\""
    echo ""
    echo "  # Specify provider"
    echo "  curllm chat --provider qwen \"Explain machine learning\""
    echo ""
    echo "  # Specify provider and model"
    echo "  curllm chat --provider groq --model llama3-8b-8192 \"Write a bash script\""
    echo ""
    echo "  # Enable verbose logging"
    echo "  curllm chat --verbose \"Debug this complex prompt\""
    echo ""
    echo "  # Use mock mode for testing"
    echo "  MOCK_MODE=true curllm chat \"Test without API keys\""
    echo ""
    echo "  # Multi-line prompt using heredoc"
    echo "  curllm chat << 'EOF'"
    echo "  Analyze this code and suggest improvements:"
    echo "  def fibonacci(n):"
    echo "      if n <= 1:"
    echo "          return n"
    echo "      else:"
    echo "          return fibonacci(n-1) + fibonacci(n-2)"
    echo "  EOF"
    echo ""
    echo "LOGGING:"
    echo "  Log file: ~/.cache/curllm/curllm.log"
    echo "  Log levels: ERROR, WARN, INFO, DEBUG"
    echo "  Enable DEBUG level with --verbose flag"
    echo ""
    echo "SECURITY:"
    echo "  API keys are stored in ~/.config/curllm/config"
    echo "  Set permissions: chmod 600 ~/.config/curllm/config"
    echo "  Keys are validated before making API requests"
    echo ""
    echo "DEVELOPMENT:"
    echo "  Extensive test suite: 50+ test files"
    echo "  Mock mode for testing without API calls"
    echo "  Modular provider system for easy extensions"
    echo ""
    echo "For complete documentation, visit: https://github.com/AR-92/curllm"
}

# Function to display help for specific command
show_command_help() {
    local command="$1"
    case "$command" in
        "chat")
            echo "CHAT COMMAND"
            echo "============"
            echo ""
            echo "Send a chat completion request to an LLM provider."
            echo ""
            echo "USAGE:"
            echo "  curllm chat [OPTIONS] <prompt>"
            echo ""
            echo "ARGUMENTS:"
            echo "  prompt    The text prompt to send to the LLM"
            echo "            Can be a single string or multi-line text"
            echo ""
            echo "OPTIONS:"
            echo "  --provider <name>    Specify LLM provider"
            echo "  --model <name>       Specify model name"
            echo "  --verbose            Enable detailed logging"
            echo ""
            echo "EXAMPLES:"
            echo "  curllm chat \"What is artificial intelligence?\""
            echo "  curllm chat --provider anthropic \"Compare Python and JavaScript\""
            echo "  curllm chat --provider groq --model llama3-8b-8192 \"Optimize this code\""
            echo "  curllm chat --verbose \"Debug this complex prompt\""
            ;;
        "help")
            echo "HELP COMMAND"
            echo "============"
            echo ""
            echo "Show help information about curllm."
            echo ""
            echo "USAGE:"
            echo "  curllm help [OPTIONS]"
            echo ""
            echo "OPTIONS:"
            echo "  --verbose    Show detailed help information"
            echo ""
            echo "EXAMPLES:"
            echo "  curllm help"
            echo "  curllm help --verbose"
            echo "  curllm --help"
            echo "  curllm -h"
            ;;
        "version")
            echo "VERSION COMMAND"
            echo "==============="
            echo ""
            echo "Show version information for curllm."
            echo ""
            echo "USAGE:"
            echo "  curllm version"
            echo ""
            echo "EXAMPLES:"
            echo "  curllm version"
            echo "  curllm --version"
            echo "  curllm -v"
            ;;
        *)
            echo "Unknown command: $command"
            echo "Use 'curllm help' for available commands"
            ;;
    esac
}